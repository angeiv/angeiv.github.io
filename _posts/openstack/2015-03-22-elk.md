---
layout: post
title: ELK日志分析
category: OpenStack
tags: ELK
keywords: ELK 日志分析 ElasticSearch LogStash Kibana Redis OpenStack
description:
---

## 平台结构


Shipper(LogStash) *n --------> Broker(Redis) -----> Indexer(LogStash) ------> Search&Store(ElasticSearch) -----> WebInterface(Kibana)

示例环境

- 中心：	192.168.1.100 redis,agent(LogStash),ElasticSearch,Kibana
- 远程：	192.168.1.101 agent(LogStash)
- 系统：	不做要求，测试环境Ubuntu Server 14.04.2 LTS 64-bit
- JRE：		openjdk-7-jre 7u75
- Redis：	2.8.4
- LogStash：	1.4.2
- ElasticSearch：	1.4.4
- Kibana：	4.0.1

## 部署

### 1. 部署ElasticSearch

```
wget https://download.elasticsearch.org/elasticsearch/elasticsearch/elasticsearch-1.4.4.tar.gz
tar zxvf elasticsearch-1.4.4.tar.gz -C /usr/local
cd /usr/local
ln -s elasticsearch-1.4.4 elasticsearch
cd elasticsearch
```

根据需要修改配置文件，默认cluster name为：elasticsearch

启动：

`bin/elasticsearch -d`

### 2. 中心安装redis

```
apt-get install redis-server
```

修改/etc/redis/redis.conf

```
daemonize yes
port 6379
bind 192.168.1.100
logfile /var/log/redis/redis-server.log
appendonly yes
```

重启redis-server

```
service redis-server restart
```

### 3. 部署中心LogStash

```
wget https://download.elasticsearch.org/logstash/logstash/logstash-1.4.2.tar.gz
tar zxvf logstash-1.4.2.tar.gz -C /usr/local/
cd /usr/local
ln -s logstash-1.4.2 logstash
cd logstash
mkdir conf logs
```

配置文件conf/central.conf

```
input {
	redis {
		host => "192.168.1.100"
		port => 6379
		type => "redis-input"
		data_type => "list"
		key => "key_count"
	}
}

output {
	stdout {}
	elasticsearch {
		cluster => "elasticsearch"
		codec => "json"
		protocol => "http"
	}
}
```

> 需要启动ElasticSearch后才能启动LogStash，因为上面配置文件的output指向的是ElasticSearch

启动：

`bin/logstash agent --verbose --config conf/central.conf --log logs/stdout.log`

配置文件表示输入来自于redis，使用redis的list类型存储数据，key为"key_count"；输出到elasticsearch，cluster的名称为"elasticsearch";

> 根据自身需要设置运行方式

### 4. 部署Kibana

```
wget https://download.elasticsearch.org/kibana/kibana/kibana-4.0.1-linux-x64.tar.gz
tar zxvf kibana-4.0.1-linux-x64 -C /usr/local
cd /usr/local
ln -s kibana-4.0.1-linux-x64 kibana
cd kibana
```

修改配置文件config/kibana.yml

```
port: 5601
host: "192.168.1.100"
elasticsearch_url: "http://192.168.1.100:9200"
```

启动：

`bin/kibana`

访问地址：

`http://192.168.1.100/5601`

### 5. 部署远程LogStash

与部署中心相似，配置文件不一样

1. 安装java运行环境
2. 安装LogStash

配置文件conf/shipper.conf

```
input {
	file {
		type => "type_count"
		path => ["/data/logs/count/stdout.log", "/data/logs/count/stderr.log"]
		exclude => ["*.gz", "access.log"]
	}
}

output {
	stdout {}
	redis {
		host => "192.168.1.100"
		port => 6379
		data_type => "list"
		key => "key_count"
	}
}
```

配置文件表示输入来自于目录`/data/logs/count/`下的`stdout.log`和`stderr.log`两个文件，且排除该目录下所有`.gz`文件和`access.log`；(这里因为path没有使用通配符，所以exclude是没有效果的)；输出表示将监听到的event发送到redis服务器，使用redis的list保存，key为”key_count”，这里的`data_type`属性和`key`属性应该与中心agent的配置一致

> 这里测试的时候需要确保这个目录和文件存在。根据自身需要配置所要收集的日志文件。

## 后续计划

将ELK这一套环境用来监控OpenStack环境。

## 参考文档

1. [http://nkcoder.github.io/blog/20141031/elkr-log-platform-deploy/](http://nkcoder.github.io/blog/20141031/elkr-log-platform-deploy/)
2. [http://www.elastic.co/guide/](http://www.elastic.co/guide/)

> 感谢原作者
